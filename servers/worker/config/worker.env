# MCP AI Development Server Configuration
# Configuration for AI-powered development tools using local Ollama LLMs

# Ollama API settings
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=codellama:7b
OLLAMA_TIMEOUT=30

# AI development settings
AI_CODE_OPTIMIZATION=true
AI_TEST_GENERATION=true
AI_DOCUMENTATION=true
AI_CODE_REVIEW=true

# Code analysis settings
MAX_FILE_SIZE_KB=500
ANALYSIS_TIMEOUT_SECONDS=60

# Logging and debugging
AI_DEV_LOG_LEVEL=INFO
AI_DEV_DEBUG_MODE=false

# Performance tuning
MAX_CONCURRENT_REQUESTS=3
REQUEST_QUEUE_SIZE=10
